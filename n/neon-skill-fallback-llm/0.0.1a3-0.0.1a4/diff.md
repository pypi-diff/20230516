# Comparing `tmp/neon_skill_fallback_llm-0.0.1a3-py3-none-any.whl.zip` & `tmp/neon_skill_fallback_llm-0.0.1a4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,36 +1,40 @@
-Zip file size: 26258 bytes, number of entries: 34
--rw-r--r--  2.0 unx    11431 b- defN 23-May-13 01:22 skill_fallback_llm/LICENSE
--rw-r--r--  2.0 unx     1635 b- defN 23-May-13 01:22 skill_fallback_llm/LICENSE.md
--rw-r--r--  2.0 unx      152 b- defN 23-May-13 01:22 skill_fallback_llm/MANIFEST.in
--rw-r--r--  2.0 unx      825 b- defN 23-May-13 01:22 skill_fallback_llm/README.md
--rw-r--r--  2.0 unx     7744 b- defN 23-May-13 01:22 skill_fallback_llm/__init__.py
--rw-r--r--  2.0 unx     1639 b- defN 23-May-13 01:22 skill_fallback_llm/skill.json
--rw-r--r--  2.0 unx     1856 b- defN 23-May-13 01:22 skill_fallback_llm/version.py
--rw-r--r--  2.0 unx       31 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/dialog/end_chat.dialog
--rw-r--r--  2.0 unx       41 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/dialog/fallback_disabled.dialog
--rw-r--r--  2.0 unx       59 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/dialog/fallback_enabled.dialog
--rw-r--r--  2.0 unx       42 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/dialog/no_chatgpt.dialog
--rw-r--r--  2.0 unx       42 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/dialog/notify_llm_active.dialog
--rw-r--r--  2.0 unx       72 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/dialog/start_chat.dialog
--rw-r--r--  2.0 unx       60 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/intent/ask_chatgpt.intent
--rw-r--r--  2.0 unx       70 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/intent/chat_with_llm.intent
--rw-r--r--  2.0 unx       80 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/intent/disable_fallback.intent
--rw-r--r--  2.0 unx       79 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/intent/enable_fallback.intent
--rw-r--r--  2.0 unx       36 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/intent/llm.entity
--rw-r--r--  2.0 unx       36 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/vocab/chat_gpt.voc
--rw-r--r--  2.0 unx       38 b- defN 23-May-13 01:22 skill_fallback_llm/locale/en-us/vocab/exit.voc
--rw-r--r--  2.0 unx     1117 b- defN 23-May-13 01:22 skill_fallback_llm/neon_skill_fallback_llm.egg-info/PKG-INFO
--rw-r--r--  2.0 unx      890 b- defN 23-May-13 01:22 skill_fallback_llm/neon_skill_fallback_llm.egg-info/SOURCES.txt
--rw-r--r--  2.0 unx        1 b- defN 23-May-13 01:22 skill_fallback_llm/neon_skill_fallback_llm.egg-info/dependency_links.txt
--rw-r--r--  2.0 unx       82 b- defN 23-May-13 01:22 skill_fallback_llm/neon_skill_fallback_llm.egg-info/entry_points.txt
--rw-r--r--  2.0 unx       90 b- defN 23-May-13 01:22 skill_fallback_llm/neon_skill_fallback_llm.egg-info/requires.txt
--rw-r--r--  2.0 unx       19 b- defN 23-May-13 01:22 skill_fallback_llm/neon_skill_fallback_llm.egg-info/top_level.txt
--rw-r--r--  2.0 unx     4893 b- defN 23-May-13 01:22 skill_fallback_llm/test/test_skill.py
--rw-r--r--  2.0 unx    11431 b- defN 23-May-13 01:22 neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE
--rw-r--r--  2.0 unx     1635 b- defN 23-May-13 01:22 neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE.md
--rw-r--r--  2.0 unx     1279 b- defN 23-May-13 01:22 neon_skill_fallback_llm-0.0.1a3.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-May-13 01:22 neon_skill_fallback_llm-0.0.1a3.dist-info/WHEEL
--rw-r--r--  2.0 unx       82 b- defN 23-May-13 01:22 neon_skill_fallback_llm-0.0.1a3.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       19 b- defN 23-May-13 01:22 neon_skill_fallback_llm-0.0.1a3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3569 b- defN 23-May-13 01:22 neon_skill_fallback_llm-0.0.1a3.dist-info/RECORD
-34 files, 51167 bytes uncompressed, 20198 bytes compressed:  60.5%
+Zip file size: 28481 bytes, number of entries: 38
+-rw-r--r--  2.0 unx    11431 b- defN 23-May-15 22:40 skill_fallback_llm/LICENSE
+-rw-r--r--  2.0 unx     1635 b- defN 23-May-15 22:40 skill_fallback_llm/LICENSE.md
+-rw-r--r--  2.0 unx      152 b- defN 23-May-15 22:40 skill_fallback_llm/MANIFEST.in
+-rw-r--r--  2.0 unx      970 b- defN 23-May-15 22:40 skill_fallback_llm/README.md
+-rw-r--r--  2.0 unx     9290 b- defN 23-May-15 22:40 skill_fallback_llm/__init__.py
+-rw-r--r--  2.0 unx     1791 b- defN 23-May-15 22:40 skill_fallback_llm/skill.json
+-rw-r--r--  2.0 unx     1856 b- defN 23-May-15 22:40 skill_fallback_llm/version.py
+-rw-r--r--  2.0 unx       31 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/end_chat.dialog
+-rw-r--r--  2.0 unx       41 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/fallback_disabled.dialog
+-rw-r--r--  2.0 unx       59 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/fallback_enabled.dialog
+-rw-r--r--  2.0 unx       42 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/no_chat_history.dialog
+-rw-r--r--  2.0 unx       42 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/no_chatgpt.dialog
+-rw-r--r--  2.0 unx       55 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/no_email_address.dialog
+-rw-r--r--  2.0 unx       42 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/notify_llm_active.dialog
+-rw-r--r--  2.0 unx       71 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/sending_chat_history.dialog
+-rw-r--r--  2.0 unx       72 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/dialog/start_chat.dialog
+-rw-r--r--  2.0 unx       60 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/intent/ask_chatgpt.intent
+-rw-r--r--  2.0 unx       70 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/intent/chat_with_llm.intent
+-rw-r--r--  2.0 unx       80 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/intent/disable_fallback.intent
+-rw-r--r--  2.0 unx      124 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/intent/email_chat_history.intent
+-rw-r--r--  2.0 unx       79 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/intent/enable_fallback.intent
+-rw-r--r--  2.0 unx       36 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/intent/llm.entity
+-rw-r--r--  2.0 unx       36 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/vocab/chat_gpt.voc
+-rw-r--r--  2.0 unx       38 b- defN 23-May-15 22:40 skill_fallback_llm/locale/en-us/vocab/exit.voc
+-rw-r--r--  2.0 unx     1262 b- defN 23-May-15 22:40 skill_fallback_llm/neon_skill_fallback_llm.egg-info/PKG-INFO
+-rw-r--r--  2.0 unx     1071 b- defN 23-May-15 22:40 skill_fallback_llm/neon_skill_fallback_llm.egg-info/SOURCES.txt
+-rw-r--r--  2.0 unx        1 b- defN 23-May-15 22:40 skill_fallback_llm/neon_skill_fallback_llm.egg-info/dependency_links.txt
+-rw-r--r--  2.0 unx       82 b- defN 23-May-15 22:40 skill_fallback_llm/neon_skill_fallback_llm.egg-info/entry_points.txt
+-rw-r--r--  2.0 unx       90 b- defN 23-May-15 22:40 skill_fallback_llm/neon_skill_fallback_llm.egg-info/requires.txt
+-rw-r--r--  2.0 unx       19 b- defN 23-May-15 22:40 skill_fallback_llm/neon_skill_fallback_llm.egg-info/top_level.txt
+-rw-r--r--  2.0 unx     6772 b- defN 23-May-15 22:40 skill_fallback_llm/test/test_skill.py
+-rw-r--r--  2.0 unx    11431 b- defN 23-May-15 22:40 neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1635 b- defN 23-May-15 22:40 neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE.md
+-rw-r--r--  2.0 unx     1424 b- defN 23-May-15 22:40 neon_skill_fallback_llm-0.0.1a4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-15 22:40 neon_skill_fallback_llm-0.0.1a4.dist-info/WHEEL
+-rw-r--r--  2.0 unx       82 b- defN 23-May-15 22:40 neon_skill_fallback_llm-0.0.1a4.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       19 b- defN 23-May-15 22:40 neon_skill_fallback_llm-0.0.1a4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4044 b- defN 23-May-15 22:40 neon_skill_fallback_llm-0.0.1a4.dist-info/RECORD
+38 files, 56127 bytes uncompressed, 21611 bytes compressed:  61.5%
```

## zipnote {}

```diff
@@ -24,32 +24,44 @@
 
 Filename: skill_fallback_llm/locale/en-us/dialog/fallback_disabled.dialog
 Comment: 
 
 Filename: skill_fallback_llm/locale/en-us/dialog/fallback_enabled.dialog
 Comment: 
 
+Filename: skill_fallback_llm/locale/en-us/dialog/no_chat_history.dialog
+Comment: 
+
 Filename: skill_fallback_llm/locale/en-us/dialog/no_chatgpt.dialog
 Comment: 
 
+Filename: skill_fallback_llm/locale/en-us/dialog/no_email_address.dialog
+Comment: 
+
 Filename: skill_fallback_llm/locale/en-us/dialog/notify_llm_active.dialog
 Comment: 
 
+Filename: skill_fallback_llm/locale/en-us/dialog/sending_chat_history.dialog
+Comment: 
+
 Filename: skill_fallback_llm/locale/en-us/dialog/start_chat.dialog
 Comment: 
 
 Filename: skill_fallback_llm/locale/en-us/intent/ask_chatgpt.intent
 Comment: 
 
 Filename: skill_fallback_llm/locale/en-us/intent/chat_with_llm.intent
 Comment: 
 
 Filename: skill_fallback_llm/locale/en-us/intent/disable_fallback.intent
 Comment: 
 
+Filename: skill_fallback_llm/locale/en-us/intent/email_chat_history.intent
+Comment: 
+
 Filename: skill_fallback_llm/locale/en-us/intent/enable_fallback.intent
 Comment: 
 
 Filename: skill_fallback_llm/locale/en-us/intent/llm.entity
 Comment: 
 
 Filename: skill_fallback_llm/locale/en-us/vocab/chat_gpt.voc
@@ -75,29 +87,29 @@
 
 Filename: skill_fallback_llm/neon_skill_fallback_llm.egg-info/top_level.txt
 Comment: 
 
 Filename: skill_fallback_llm/test/test_skill.py
 Comment: 
 
-Filename: neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE
+Filename: neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE
 Comment: 
 
-Filename: neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE.md
+Filename: neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE.md
 Comment: 
 
-Filename: neon_skill_fallback_llm-0.0.1a3.dist-info/METADATA
+Filename: neon_skill_fallback_llm-0.0.1a4.dist-info/METADATA
 Comment: 
 
-Filename: neon_skill_fallback_llm-0.0.1a3.dist-info/WHEEL
+Filename: neon_skill_fallback_llm-0.0.1a4.dist-info/WHEEL
 Comment: 
 
-Filename: neon_skill_fallback_llm-0.0.1a3.dist-info/entry_points.txt
+Filename: neon_skill_fallback_llm-0.0.1a4.dist-info/entry_points.txt
 Comment: 
 
-Filename: neon_skill_fallback_llm-0.0.1a3.dist-info/top_level.txt
+Filename: neon_skill_fallback_llm-0.0.1a4.dist-info/top_level.txt
 Comment: 
 
-Filename: neon_skill_fallback_llm-0.0.1a3.dist-info/RECORD
+Filename: neon_skill_fallback_llm-0.0.1a4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## skill_fallback_llm/README.md

```diff
@@ -5,19 +5,23 @@
 
 ## Description
 Converse with an LLM and enable LLM responses when Neon doesn't have a better
 response.
 
 To send a single query to an LLM, you can ask Neon to "ask Chat GPT <something>".
 To start conversing with an LLM, ask to "talk to Chat GPT" and have all of your input
-sent to an LLM until you say goodbye or stop talking for awhile.
+sent to an LLM until you say goodbye or stop talking for a while.
 
 Enable fallback behavior by asking to "enable LLM fallback skill" or disable it
 by asking to "disable LLM fallback".
 
+To have a copy of LLM interactions sent via email, ask Neon to 
+"email me a copy of our conversation".
+
 ## Examples 
 
 * "Explain quantum computing in simple terms"
 * "Ask chat GPT what an LLM is"
 * "Talk to chat GPT"
 * "Enable LLM fallback skill"
 * "Disable LLM fallback skill"
+* "Email me a copy of our conversation"
```

## skill_fallback_llm/__init__.py

```diff
@@ -28,25 +28,27 @@
 from enum import Enum
 from threading import Thread
 from time import time
 
 from ovos_utils import classproperty
 from ovos_utils.log import LOG
 from ovos_utils.process_utils import RuntimeRequirements
-from ovos_workshop.skills.fallback import FallbackSkill
+# from ovos_workshop.skills.fallback import FallbackSkill
+from neon_utils.skills.neon_fallback_skill import NeonFallbackSkill, NeonSkill
 from neon_utils.message_utils import get_message_user
+from neon_utils.user_utils import get_user_prefs
 from neon_mq_connector.utils.client_utils import send_mq_request
 from mycroft.skills.mycroft_skill.decorators import intent_file_handler
 
 
 class LLM(Enum):
     GPT = "Chat GPT"
 
 
-class LLMSkill(FallbackSkill):
+class LLMSkill(NeonFallbackSkill):
     @classproperty
     def runtime_requirements(self):
         return RuntimeRequirements(internet_before_load=True,
                                    network_before_load=True,
                                    gui_before_load=False,
                                    requires_internet=True,
                                    requires_network=True,
@@ -119,19 +121,48 @@
             llm = LLM.GPT
         else:
             LOG.warning(f"Requested invalid LLM: {llm}")
             llm = LLM.GPT
         self.speak_dialog("start_chat", {"llm": llm.value})
         self._reset_expiration(user)
 
+    @intent_file_handler("email_chat_history.intent")
+    def handle_email_chat_history(self, message):
+        user_prefs = get_user_prefs(message)['user']
+        username = user_prefs['username']
+        email_addr = user_prefs['email']
+        if username not in self.chat_history:
+            LOG.debug(f"No history for {username}")
+            self.speak_dialog("no_chat_history", private=True)
+            return
+        if not email_addr:
+            LOG.debug("No email address")
+            # TODO: Capture Email address
+            self.speak_dialog("no_email_address", private=True)
+            return
+        self.speak_dialog("sending_chat_history",
+                          {"email": email_addr}, private=True)
+        self._send_email(username, email_addr)
+
+    def _send_email(self, username: str, email: str):
+        history = self.chat_history.get(username)
+        email_text = ""
+        for entry in history:
+            formatted = entry[1].replace('\n\n', '\n').replace('\n', '\n\t...')
+            email_text += f"[{entry[0]}] {formatted}\n"
+        NeonSkill.send_email(self, "LLM Conversation", email_text,
+                             email_addr=email)
+
     def _stop_chatting(self, message):
         user = get_message_user(message) or self._default_user
         self.gui.remove_controlled_notification()
         self.chatting.pop(user)
         self.speak_dialog("end_chat")
+        event_name = f"end_converse.{user}"
+        self.cancel_scheduled_event(event_name)
 
     def _get_llm_response(self, query: str, user: str) -> str:
         """
         Get a response from an LLM
         :param query: User utterance to generate a response to
         :param user: Username making the request
         :returns: Speakable response to the user's query
@@ -139,29 +170,31 @@
         # TODO: support multiple LLM backends?
         self.chat_history.setdefault(user, list())
         mq_resp = send_mq_request("/llm", {"query": query,
                                            "history": self.chat_history[user]},
                                   "chat_gpt_input")
         resp = mq_resp.get("response") or ""
         if resp:
-            self.chat_history[user].append(("user", query))
+            username = "user" if user == self._default_user else user
+            self.chat_history[user].append((username, query))
             self.chat_history[user].append(("llm", resp))
         LOG.debug(f"Got LLM response: {resp}")
         return resp
 
     def converse(self, message=None):
         user = get_message_user(message) or self._default_user
         if user not in self.chatting:
             return False
         last_message = self.chatting[user]
         if time() - last_message > self.chat_timeout_seconds:
             LOG.info(f"Chat session timed out")
             self._stop_chatting(message)
             return False
-        utterance = message.data.get('utterances', [])[0]
+        # Take final utterance as one that wasn't normalized
+        utterance = message.data.get('utterances', [""])[-1]
         if self.voc_match(utterance, "exit"):
             self._stop_chatting(message)
             return True
         Thread(target=self._threaded_converse, args=(utterance, user),
                daemon=True).start()
         return True
```

## skill_fallback_llm/skill.json

### Pretty-printed

 * *Similarity: 0.9734848484848485%*

 * *Differences: {"'description'": "'Converse with an LLM and enable LLM responses when Neon doesn\\'t have a "*

 * *                  'better response. To send a single query to an LLM, you can ask Neon to "ask '*

 * *                  'Chat GPT <something>". To start conversing with an LLM, ask to "talk to Chat '*

 * *                  'GPT" and have all of your input sent to an LLM until you say goodbye or stop '*

 * *                  'talking for a while. Enable fallback behavior by asking to "enable LLM fallback '*

 * *                  'skil […]*

```diff
@@ -1,21 +1,22 @@
 {
     "authorname": "NeonGeckoCom",
     "branch": "master",
     "categories": [],
     "category": "",
     "credits": [],
-    "description": "Converse with an LLM and enable LLM responses when Neon doesn't have a better response. To send a single query to an LLM, you can ask Neon to \"ask Chat GPT <something>\". To start conversing with an LLM, ask to \"talk to Chat GPT\" and have all of your input sent to an LLM until you say goodbye or stop talking for awhile. Enable fallback behavior by asking to \"enable LLM fallback skill\" or disable it by asking to \"disable LLM fallback\".",
+    "description": "Converse with an LLM and enable LLM responses when Neon doesn't have a better response. To send a single query to an LLM, you can ask Neon to \"ask Chat GPT <something>\". To start conversing with an LLM, ask to \"talk to Chat GPT\" and have all of your input sent to an LLM until you say goodbye or stop talking for a while. Enable fallback behavior by asking to \"enable LLM fallback skill\" or disable it by asking to \"disable LLM fallback\". To have a copy of LLM interactions sent via email, ask Neon to \"email me a copy of our conversation\".",
     "desktopFile": false,
     "examples": [
         "Explain quantum computing in simple terms",
         "Ask chat GPT what an LLM is",
         "Talk to chat GPT",
         "Enable LLM fallback skill",
-        "Disable LLM fallback skill"
+        "Disable LLM fallback skill",
+        "Email me a copy of our conversation"
     ],
     "foldername": null,
     "icon": "logo.svg",
     "incompatible_skills": [],
     "license": "BSD-3-Clause",
     "platforms": [
         "i386",
```

## skill_fallback_llm/version.py

```diff
@@ -22,8 +22,8 @@
 # EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 # PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA,
 # OR PROFITS;  OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 # LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 # NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 # SOFTWARE,  EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
-__version__ = "0.0.1a3"
+__version__ = "0.0.1a4"
```

## skill_fallback_llm/neon_skill_fallback_llm.egg-info/PKG-INFO

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: neon-skill-fallback-llm
-Version: 0.0.1a3
+Version: 0.0.1a4
 Home-page: https://github.com/NeonGeckoCom/skill-fallback_llm
 Author: Neongecko
 Author-email: developers@neon.ai
 License: BSD-3-Clause
 Description-Content-Type: text/markdown
 License-File: LICENSE
 License-File: LICENSE.md
@@ -16,19 +16,23 @@
 
 ## Description
 Converse with an LLM and enable LLM responses when Neon doesn't have a better
 response.
 
 To send a single query to an LLM, you can ask Neon to "ask Chat GPT <something>".
 To start conversing with an LLM, ask to "talk to Chat GPT" and have all of your input
-sent to an LLM until you say goodbye or stop talking for awhile.
+sent to an LLM until you say goodbye or stop talking for a while.
 
 Enable fallback behavior by asking to "enable LLM fallback skill" or disable it
 by asking to "disable LLM fallback".
 
+To have a copy of LLM interactions sent via email, ask Neon to 
+"email me a copy of our conversation".
+
 ## Examples 
 
 * "Explain quantum computing in simple terms"
 * "Ask chat GPT what an LLM is"
 * "Talk to chat GPT"
 * "Enable LLM fallback skill"
 * "Disable LLM fallback skill"
+* "Email me a copy of our conversation"
```

## skill_fallback_llm/neon_skill_fallback_llm.egg-info/SOURCES.txt

```diff
@@ -5,20 +5,24 @@
 __init__.py
 setup.py
 skill.json
 version.py
 locale/en-us/dialog/end_chat.dialog
 locale/en-us/dialog/fallback_disabled.dialog
 locale/en-us/dialog/fallback_enabled.dialog
+locale/en-us/dialog/no_chat_history.dialog
 locale/en-us/dialog/no_chatgpt.dialog
+locale/en-us/dialog/no_email_address.dialog
 locale/en-us/dialog/notify_llm_active.dialog
+locale/en-us/dialog/sending_chat_history.dialog
 locale/en-us/dialog/start_chat.dialog
 locale/en-us/intent/ask_chatgpt.intent
 locale/en-us/intent/chat_with_llm.intent
 locale/en-us/intent/disable_fallback.intent
+locale/en-us/intent/email_chat_history.intent
 locale/en-us/intent/enable_fallback.intent
 locale/en-us/intent/llm.entity
 locale/en-us/vocab/chat_gpt.voc
 locale/en-us/vocab/exit.voc
 neon_skill_fallback_llm.egg-info/PKG-INFO
 neon_skill_fallback_llm.egg-info/SOURCES.txt
 neon_skill_fallback_llm.egg-info/dependency_links.txt
```

## skill_fallback_llm/test/test_skill.py

```diff
@@ -104,13 +104,63 @@
     def test_handle_chat_with_llm(self):
         fake_msg = Message("test", {},
                            {"username": "test_user"})
         self.skill.chatting = dict()
         self.skill.handle_chat_with_llm(fake_msg)
         self.assertIsInstance(self.skill.chatting["test_user"], float)
 
+    def test_handle_email_chat_history(self):
+        real_send_email = self.skill._send_email
+        self.skill._send_email = Mock()
+
+        from neon_utils.user_utils import get_default_user_config
+        default_profile = get_default_user_config()
+        default_profile['user']['username'] = 'test_user'
+        default_profile['user']['email'] = ''
+        test_message = Message("", {}, {"username": "test_user",
+                                        "user_profiles": [default_profile]})
+        # No Chat History
+        self.skill.handle_email_chat_history(test_message)
+        self.skill.speak_dialog.assert_called_once_with("no_chat_history",
+                                                        private=True)
+
+        # No Email Address
+        self.skill.chat_history['test_user'] = [("user", "hey"), ("llm", "hi")]
+        self.skill.handle_email_chat_history(test_message)
+        self.skill.speak_dialog.assert_called_with("no_email_address",
+                                                   private=True)
+
+        # Valid Request
+        test_message.context['user_profiles'][0]['user']['email'] = \
+            "test@neon.ai"
+        self.skill.handle_email_chat_history(test_message)
+        self.skill.speak_dialog.assert_called_with("sending_chat_history",
+                                                   {"email": "test@neon.ai"},
+                                                   private=True)
+        self.skill._send_email.assert_called_once_with("test_user",
+                                                       "test@neon.ai")
+
+        self.skill._send_email = real_send_email
+
     def test_converse(self):
         # TODO
         pass
 
+    def test_threaded_converse(self):
+        # TODO
+        pass
+
+    def test_reset_expiration(self):
+        # TODO
+        pass
+
+    def test_stop_chatting(self):
+        # TODO
+        pass
+
+    def test_send_email(self):
+        # TODO
+        pass
+
+
 if __name__ == '__main__':
     unittest.main()
```

## Comparing `neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE` & `neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE.md` & `neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `neon_skill_fallback_llm-0.0.1a3.dist-info/METADATA` & `neon_skill_fallback_llm-0.0.1a4.dist-info/METADATA`

 * *Files 22% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: neon-skill-fallback-llm
-Version: 0.0.1a3
+Version: 0.0.1a4
 Home-page: https://github.com/NeonGeckoCom/skill-fallback_llm
 Author: Neongecko
 Author-email: developers@neon.ai
 License: BSD-3-Clause
 Description-Content-Type: text/markdown
 License-File: LICENSE
 License-File: LICENSE.md
@@ -20,19 +20,23 @@
 
 ## Description
 Converse with an LLM and enable LLM responses when Neon doesn't have a better
 response.
 
 To send a single query to an LLM, you can ask Neon to "ask Chat GPT <something>".
 To start conversing with an LLM, ask to "talk to Chat GPT" and have all of your input
-sent to an LLM until you say goodbye or stop talking for awhile.
+sent to an LLM until you say goodbye or stop talking for a while.
 
 Enable fallback behavior by asking to "enable LLM fallback skill" or disable it
 by asking to "disable LLM fallback".
 
+To have a copy of LLM interactions sent via email, ask Neon to 
+"email me a copy of our conversation".
+
 ## Examples 
 
 * "Explain quantum computing in simple terms"
 * "Ask chat GPT what an LLM is"
 * "Talk to chat GPT"
 * "Enable LLM fallback skill"
 * "Disable LLM fallback skill"
+* "Email me a copy of our conversation"
```

## Comparing `neon_skill_fallback_llm-0.0.1a3.dist-info/RECORD` & `neon_skill_fallback_llm-0.0.1a4.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,34 +1,38 @@
 skill_fallback_llm/LICENSE,sha256=Say7sFhMWFZjsayrsgHilF-61WjPO02-sBrHVI2t34Y,11431
 skill_fallback_llm/LICENSE.md,sha256=KxXbLh0XZkaLbNrj5ksC1Hl04EeiMbY-I0pGhKTPBRc,1635
 skill_fallback_llm/MANIFEST.in,sha256=uLqssPUQG-XLNNb4xNDkJtVtMkY4PzLRloqAIux8atk,152
-skill_fallback_llm/README.md,sha256=Jt24zmcyH-oMe5Fl8up7tGP7Q45xhX-KFubuAV072ZI,825
-skill_fallback_llm/__init__.py,sha256=0UlXlwv_7gDlAmp93jiTpSlLeoLKf77t6xy1hVEyfeY,7744
-skill_fallback_llm/skill.json,sha256=WDbh5wfihuc3Rgmcsvm7biLXMeJerFlwCJ_aDjcdAMs,1639
-skill_fallback_llm/version.py,sha256=_qvxiLhKBg_ex2lxNDS1iOoBF-DY2z22O6eJL_pHQuA,1856
+skill_fallback_llm/README.md,sha256=bvqumzHyPVQkqJ_mkJlePm2vuEdBtKymy-X8LdIJm4M,970
+skill_fallback_llm/__init__.py,sha256=dDf_pELRCRhlghNpWff8d7CK40oLNcvdKNm_ugwF44Y,9290
+skill_fallback_llm/skill.json,sha256=GBmwgeIwEhEqLUPKLuzgJNd_RZnk2HrOYeBovxHgcEY,1791
+skill_fallback_llm/version.py,sha256=oI8sX4X-4ECbOUTCvaASMdfcG3y6SR7YHdubXf9ipSU,1856
 skill_fallback_llm/locale/en-us/dialog/end_chat.dialog,sha256=PYlIROYNmcoaNLBL5afLR7DolP_uA_NeBH0uJVCG09c,31
 skill_fallback_llm/locale/en-us/dialog/fallback_disabled.dialog,sha256=OgHJuNlqQXcnImr78zFFJ5INgPGBpRqHB_yFu-al-BU,41
 skill_fallback_llm/locale/en-us/dialog/fallback_enabled.dialog,sha256=x_4U6Z4SzcojeM5Wq4hgkGpT4YYsYp0STyZOcPjOcLM,59
+skill_fallback_llm/locale/en-us/dialog/no_chat_history.dialog,sha256=QabRePAX09iLagBGIf1ZLEudusk08h7cwFVAN2DnTI0,42
 skill_fallback_llm/locale/en-us/dialog/no_chatgpt.dialog,sha256=8qk52mNZDeOGpYP4saw7HLvasq6wq19_ZFTIBMosYWQ,42
+skill_fallback_llm/locale/en-us/dialog/no_email_address.dialog,sha256=dr5jsxcDUk-mhARwk4CryaEDP7YhUvDpRCR9NngCW_g,55
 skill_fallback_llm/locale/en-us/dialog/notify_llm_active.dialog,sha256=nJg0ly4VqZ5V6xx2IvMqVL04KQJoho1foMaoI46cp3M,42
+skill_fallback_llm/locale/en-us/dialog/sending_chat_history.dialog,sha256=m7h8lOShKNrQuXnA-Xpql83sRebbauP5rOMzWFxc9_s,71
 skill_fallback_llm/locale/en-us/dialog/start_chat.dialog,sha256=9XKeU5mXJMkLdmH1Tno82hXIgfipv5_CEw6AGzjA_f8,72
 skill_fallback_llm/locale/en-us/intent/ask_chatgpt.intent,sha256=uEAGihGA2kS0uvIjNYzLQmezn54Fa8ytVQwE3I3qO-M,60
 skill_fallback_llm/locale/en-us/intent/chat_with_llm.intent,sha256=6jXDTXPy_c5luTZ6NXydQd3JuhEYMqqnIybyLC8xA78,70
 skill_fallback_llm/locale/en-us/intent/disable_fallback.intent,sha256=lhRvJOoiyQD0bnyU39ZQec7DCbtLZalVNkCTPCm7CfY,80
+skill_fallback_llm/locale/en-us/intent/email_chat_history.intent,sha256=wmclHAJAyr2bgfc0VzLpUDrcVDW0EY6CIre7zEBN7DI,124
 skill_fallback_llm/locale/en-us/intent/enable_fallback.intent,sha256=fxWermvAakHr2sFVC0wO254i9Ca-iQ7q6U5UyoKjK_k,79
 skill_fallback_llm/locale/en-us/intent/llm.entity,sha256=nXPMmALj8OzQ2iZrqr9_o-npV0NemS1T8ejulsdaa6Y,36
 skill_fallback_llm/locale/en-us/vocab/chat_gpt.voc,sha256=nXPMmALj8OzQ2iZrqr9_o-npV0NemS1T8ejulsdaa6Y,36
 skill_fallback_llm/locale/en-us/vocab/exit.voc,sha256=ZXLmG-aawUOY3KQCuJd1fmVwNvNgwNlzQeOJSWGlsko,38
-skill_fallback_llm/neon_skill_fallback_llm.egg-info/PKG-INFO,sha256=ErRBiNN4aME0M88SWjB7swL07gVtTZxueFTgL1oNfbs,1117
-skill_fallback_llm/neon_skill_fallback_llm.egg-info/SOURCES.txt,sha256=i5iHZ309DBg6Awo1Su5RZtpukOH_UnWuEZRcgKyBS3I,890
+skill_fallback_llm/neon_skill_fallback_llm.egg-info/PKG-INFO,sha256=avJIkxJ2LowfgTtJMM7XvDDHU6_CnjJiPY9vJ0Kqk5c,1262
+skill_fallback_llm/neon_skill_fallback_llm.egg-info/SOURCES.txt,sha256=qR-5UNaMDG1R7PcC1BNdTcsavs8jAbSHVCfVDUVW9zI,1071
 skill_fallback_llm/neon_skill_fallback_llm.egg-info/dependency_links.txt,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 skill_fallback_llm/neon_skill_fallback_llm.egg-info/entry_points.txt,sha256=uG0kEN5_sAXyygBQ76sJ2gbHxKk2IqUgGJSiWi8DWI0,82
 skill_fallback_llm/neon_skill_fallback_llm.egg-info/requires.txt,sha256=oHJYwAJBfaU80j9-XVA9VPKmjPjQnBQN-saftgGlr1E,90
 skill_fallback_llm/neon_skill_fallback_llm.egg-info/top_level.txt,sha256=Ox1eUvcwfxj74ehx1QnMJN39Z457UTXniWj3z7AL9aI,19
-skill_fallback_llm/test/test_skill.py,sha256=fSvXysA9xCvCzl1Ruymny_DvAY8xnS8h9LI5QfhXCmA,4893
-neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE,sha256=Say7sFhMWFZjsayrsgHilF-61WjPO02-sBrHVI2t34Y,11431
-neon_skill_fallback_llm-0.0.1a3.dist-info/LICENSE.md,sha256=KxXbLh0XZkaLbNrj5ksC1Hl04EeiMbY-I0pGhKTPBRc,1635
-neon_skill_fallback_llm-0.0.1a3.dist-info/METADATA,sha256=i0AzN8EbCVglV7f4CcPpZ7oN2z5bCeAMUbS3wnweUik,1279
-neon_skill_fallback_llm-0.0.1a3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-neon_skill_fallback_llm-0.0.1a3.dist-info/entry_points.txt,sha256=uG0kEN5_sAXyygBQ76sJ2gbHxKk2IqUgGJSiWi8DWI0,82
-neon_skill_fallback_llm-0.0.1a3.dist-info/top_level.txt,sha256=Ox1eUvcwfxj74ehx1QnMJN39Z457UTXniWj3z7AL9aI,19
-neon_skill_fallback_llm-0.0.1a3.dist-info/RECORD,,
+skill_fallback_llm/test/test_skill.py,sha256=RYjLke1WgClWOfsDruZQII34IoY9RRJXWy2fi3uagA4,6772
+neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE,sha256=Say7sFhMWFZjsayrsgHilF-61WjPO02-sBrHVI2t34Y,11431
+neon_skill_fallback_llm-0.0.1a4.dist-info/LICENSE.md,sha256=KxXbLh0XZkaLbNrj5ksC1Hl04EeiMbY-I0pGhKTPBRc,1635
+neon_skill_fallback_llm-0.0.1a4.dist-info/METADATA,sha256=0f09gADz_rqRHntG-rI3cmicOBJwiDUCjy2r10N40_Y,1424
+neon_skill_fallback_llm-0.0.1a4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+neon_skill_fallback_llm-0.0.1a4.dist-info/entry_points.txt,sha256=uG0kEN5_sAXyygBQ76sJ2gbHxKk2IqUgGJSiWi8DWI0,82
+neon_skill_fallback_llm-0.0.1a4.dist-info/top_level.txt,sha256=Ox1eUvcwfxj74ehx1QnMJN39Z457UTXniWj3z7AL9aI,19
+neon_skill_fallback_llm-0.0.1a4.dist-info/RECORD,,
```

