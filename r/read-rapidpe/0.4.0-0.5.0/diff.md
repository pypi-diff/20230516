# Comparing `tmp/read_rapidpe-0.4.0.tar.gz` & `tmp/read_rapidpe-0.5.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "read_rapidpe-0.4.0.tar", max compression
+gzip compressed data, was "read_rapidpe-0.5.0.tar", max compression
```

## Comparing `read_rapidpe-0.4.0.tar` & `read_rapidpe-0.5.0.tar`

### file list

```diff
@@ -1,10 +1,11 @@
--rw-r--r--   0        0        0     2399 2023-04-17 13:15:50.969962 read_rapidpe-0.4.0/README.md
--rw-r--r--   0        0        0      627 2023-05-13 16:32:38.750582 read_rapidpe-0.4.0/pyproject.toml
--rw-r--r--   0        0        0      353 2023-04-16 13:12:20.078578 read_rapidpe-0.4.0/read_rapidpe/__init__.py
--rw-r--r--   0        0        0    11295 2023-05-13 16:31:51.989559 read_rapidpe-0.4.0/read_rapidpe/grid_point.py
--rw-r--r--   0        0        0     6083 2023-04-16 13:20:01.614285 read_rapidpe-0.4.0/read_rapidpe/p_astro.py
--rw-r--r--   0        0        0     9718 2023-04-07 15:04:09.805939 read_rapidpe-0.4.0/read_rapidpe/parser.py
--rw-r--r--   0        0        0     1474 2023-04-16 14:05:36.413685 read_rapidpe-0.4.0/read_rapidpe/plot.py
--rw-r--r--   0        0        0    23411 2023-05-08 23:11:43.053515 read_rapidpe-0.4.0/read_rapidpe/result.py
--rw-r--r--   0        0        0     2200 2022-11-25 08:05:18.514011 read_rapidpe-0.4.0/read_rapidpe/transform.py
--rw-r--r--   0        0        0     3330 1970-01-01 00:00:00.000000 read_rapidpe-0.4.0/PKG-INFO
+-rw-r--r--   0        0        0     2399 2023-04-17 13:15:50.969962 read_rapidpe-0.5.0/README.md
+-rw-r--r--   0        0        0      627 2023-05-16 05:05:36.967467 read_rapidpe-0.5.0/pyproject.toml
+-rw-r--r--   0        0        0      353 2023-04-16 13:12:20.078578 read_rapidpe-0.5.0/read_rapidpe/__init__.py
+-rw-r--r--   0        0        0    11295 2023-05-13 16:31:51.989559 read_rapidpe-0.5.0/read_rapidpe/grid_point.py
+-rw-r--r--   0        0        0     3445 2023-05-16 05:02:30.343719 read_rapidpe-0.5.0/read_rapidpe/io.py
+-rw-r--r--   0        0        0     6083 2023-04-16 13:20:01.614285 read_rapidpe-0.5.0/read_rapidpe/p_astro.py
+-rw-r--r--   0        0        0     9718 2023-04-07 15:04:09.805939 read_rapidpe-0.5.0/read_rapidpe/parser.py
+-rw-r--r--   0        0        0     1474 2023-04-16 14:05:36.413685 read_rapidpe-0.5.0/read_rapidpe/plot.py
+-rw-r--r--   0        0        0    24548 2023-05-16 04:46:04.027718 read_rapidpe-0.5.0/read_rapidpe/result.py
+-rw-r--r--   0        0        0     2200 2022-11-25 08:05:18.514011 read_rapidpe-0.5.0/read_rapidpe/transform.py
+-rw-r--r--   0        0        0     3330 1970-01-01 00:00:00.000000 read_rapidpe-0.5.0/PKG-INFO
```

### Comparing `read_rapidpe-0.4.0/README.md` & `read_rapidpe-0.5.0/README.md`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.4.0/pyproject.toml` & `read_rapidpe-0.5.0/pyproject.toml`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [tool.poetry]
 name = "read-rapidpe"
-version = "0.4.0"
+version = "0.5.0"
 description = "Read and analyse results generated by rapidpe-rift-pipe"
 authors = ["Cory Chu <cory@gwlab.page>"]
 readme = "README.md"
 packages = [{include = "read_rapidpe"}]
 homepage = "https://github.com/c0rychu/read-rapidpe"
 repository = "https://git.ligo.org/yu-kuang.chu/read-rapidpe"
```

### Comparing `read_rapidpe-0.4.0/read_rapidpe/grid_point.py` & `read_rapidpe-0.5.0/read_rapidpe/grid_point.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.4.0/read_rapidpe/p_astro.py` & `read_rapidpe-0.5.0/read_rapidpe/p_astro.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.4.0/read_rapidpe/parser.py` & `read_rapidpe-0.5.0/read_rapidpe/parser.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.4.0/read_rapidpe/plot.py` & `read_rapidpe-0.5.0/read_rapidpe/plot.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.4.0/read_rapidpe/result.py` & `read_rapidpe-0.5.0/read_rapidpe/result.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,35 +7,32 @@
 from pathlib import Path
 from joblib import Parallel, delayed
 import re
 import numpy as np
 import h5py
 # import pandas as pd
 from .grid_point import RapidPE_grid_point
+from .io import load_event_info_dict_txt
+from .io import load_injection_info_txt
+from .io import dict_of_ndarray_to_recarray
+from .io import dict_from_hdf_group
+from .io import dict_to_hdf_group
+
 from .transform import transform_m1m2_to_mceta, transform_mceta_to_m1m2
 from .transform import jacobian_mceta_by_m1m2
 
 from matplotlib.tri import Triangulation
 from matplotlib.tri import LinearTriInterpolator, CubicTriInterpolator
 from scipy.interpolate import LinearNDInterpolator, NearestNDInterpolator
 from scipy.interpolate import CloughTocher2DInterpolator
 from scipy.stats import multinomial
 
 # import time  # for profiling
 
 
-def dict_of_ndarray_to_recarray(dict_of_ndarray):
-    # return pd.DataFrame(dict_of_ndarray).to_records(index=False)
-    keys = dict_of_ndarray.keys()
-    names = ", ".join(keys)
-    return np.core.records.fromarrays(
-        [dict_of_ndarray[key] for key in keys], names=names
-        )
-
-
 def unique_with_tolerance(array, tolerance):
     tolerance = np.abs(tolerance)
     sorted_array = np.sort(array)
     diff = np.diff(sorted_array)
     mask = np.append(True, np.where(diff < tolerance, False, True))
     return sorted_array[mask]
 
@@ -84,21 +81,21 @@
     log_likelihood(m1, m2):
         Interpolated log_likelihood
 
     """
 
     def __init__(self, result=None):
         if result is None:
-            self.grid_points = []  # FIXME: it's actually a np.array
+            self.grid_points = np.empty(0, dtype=object)
             self._keys = []
         else:
             self.grid_points = result.grid_points
             self._keys = result._keys
 
-            for attr in result._keys:
+            for attr in result._keys + ["event_info", "injection_info"]:
                 try:
                     setattr(self, attr, getattr(result, attr))
                 except AttributeError:
                     pass
             # Try:
             # self.mass_1 = result.mass_1
             # self.mass_2 = result.mass_2
@@ -106,23 +103,23 @@
             # self.spin_2z = result.spin_2z
             # self.marg_log_likelihood = result.marg_log_likelihood
             # ...
 
     @cached_property
     def intrinsic_table(self):
         """
-        Combine intrinsic tables to a single padas.DataFrame
+        Combine intrinsic tables to a single dict
         """
         # return pd.DataFrame({key: getattr(self, key) for key in self._keys})
         return {key: getattr(self, key) for key in self._keys}
 
     @cached_property
     def extrinsic_samples(self):
         """
-        Combine extrinsic samples to a single padas.DataFrame
+        Combine extrinsic samples to a single dict
         """
         # return pd.concat(
         #      [pd.DataFrame(gp.extrinsic_table) for gp in self.grid_points])
         gps = self.grid_points
         keys_ext = gps[0].extrinsic_table.keys()
         extrinsic_samples = {}
         for key in keys_ext:
@@ -152,32 +149,45 @@
 
         extrinsic_table : bool
             Whether loading extrinsic_table as well
 
         """
         result = cls()
         with h5py.File(hdf_file, "r") as f:
+            # Load grid_points
             gps = f["grid_points"]
             N = len(gps)
             result.grid_points = np.empty(N, dtype=object)
             for i, gp in enumerate(gps.values()):
                 result.grid_points[i] = \
                     RapidPE_grid_point.from_hdf_grid_point_group(
                         hdf_gp_group=gp,
                         extrinsic_table=extrinsic_table
                         )
+
+            # Load intrinsic_table
             it = f["intrinsic_table"]
             result.intrinsic_table = {key: it[key] for key in it.dtype.names}
+
+            # Load other attributes
             result._keys = list(it.dtype.names)
             for attr in result._keys:
                 try:
                     setattr(result, attr, result.intrinsic_table[attr])
                 except KeyError:
                     pass
 
+            # Load event_info and injection_info
+            for attr in ["event_info", "injection_info"]:
+                try:
+                    x = dict_from_hdf_group(f[attr])
+                    setattr(result, attr, x)
+                except KeyError:
+                    pass
+
         return cls(result)
 
     @classmethod
     def from_run_dir(cls,
                      run_dir,
                      use_numpy=True,
                      use_ligolw=True,
@@ -198,22 +208,38 @@
         use_ligolw : bool
             Whether using ligo.lw to read xml files
 
         extrinsic_table : bool
             Whether loading extrinsic_table as well
 
         """
+        run_dir = Path(run_dir)
         results_dir = Path(run_dir)/Path("results")
         xml_array = [f.as_posix() for f in sorted(results_dir.glob("*.xml.gz"))]  # noqa: E501
 
-        return cls.from_xml_array(xml_array,
-                                  use_numpy=use_numpy,
-                                  use_ligolw=use_ligolw,
-                                  extrinsic_table=extrinsic_table,
-                                  parallel_n=parallel_n)
+        result = cls.from_xml_array(xml_array,
+                                    use_numpy=use_numpy,
+                                    use_ligolw=use_ligolw,
+                                    extrinsic_table=extrinsic_table,
+                                    parallel_n=parallel_n)
+
+        event_info_dict_txt = run_dir / "event_info_dict.txt"
+        injection_info_txt = run_dir / "injection_info.txt"
+
+        try:
+            result.event_info = load_event_info_dict_txt(event_info_dict_txt)
+        except FileNotFoundError:
+            pass
+
+        try:
+            result.injection_info = load_injection_info_txt(injection_info_txt)
+        except FileNotFoundError:
+            pass
+
+        return result
 
     @classmethod
     def from_xml_array(cls,
                        xml_array,
                        use_numpy=True,
                        use_ligolw=True,
                        extrinsic_table=True,
@@ -308,14 +334,16 @@
 
         # Add chirp_mass and symmetric_mass_ratio
         if ("mass_1" in result._keys) and ("mass_2" in result._keys):
             result.chirp_mass, result.symmetric_mass_ratio = \
                 transform_m1m2_to_mceta(result.mass_1, result.mass_2)
             result._keys.extend(["chirp_mass", "symmetric_mass_ratio"])
 
+            # TODO: Addn mass_ratio q
+
         return cls(result)
 
     def to_hdf(self, hdf_filename, compression=None):
         """
         Save result to hdf file
 
         Parameters
@@ -371,14 +399,23 @@
 
                 for i, gp in enumerate(gps.values()):
                     vsource = h5py.VirtualSource(gp["extrinsic_table"])
                     layout[n_samples[i]:n_samples[i+1]] = vsource
 
                 f.create_virtual_dataset('extrinsic_samples', layout)
 
+            # Save event_info and injection_info
+            for attr in ["event_info", "injection_info"]:
+                try:
+                    x = getattr(self, attr)
+                    g = f.create_group(attr)
+                    dict_to_hdf_group(x, g)
+                except AttributeError:
+                    pass
+
     def do_interpolate_marg_log_likelihood_m1m2(
             self,
             method="linear-scipy",
             gaussian_sigma_to_grid_size_ratio=0.5
             ):
         """
         Perfom triangular interpolation of marg_log_likelihood in
```

### Comparing `read_rapidpe-0.4.0/read_rapidpe/transform.py` & `read_rapidpe-0.5.0/read_rapidpe/transform.py`

 * *Files identical despite different names*

### Comparing `read_rapidpe-0.4.0/PKG-INFO` & `read_rapidpe-0.5.0/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: read-rapidpe
-Version: 0.4.0
+Version: 0.5.0
 Summary: Read and analyse results generated by rapidpe-rift-pipe
 Home-page: https://github.com/c0rychu/read-rapidpe
 Author: Cory Chu
 Author-email: cory@gwlab.page
 Requires-Python: >=3.8,<4.0
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.8
```

